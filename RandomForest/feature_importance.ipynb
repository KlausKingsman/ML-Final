{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Data libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Analysis libs\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_data_filepath = '../datasets/Obfuscated/Obfuscated-MalMem2022_edited.csv'\n",
    "malware_data = pd.read_csv(malware_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drop_columns = ['Class', 'Category']\n",
    "X = malware_data.drop(columns=X_drop_columns)\n",
    "\n",
    "y_column = malware_data.Class\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "mi_scores = make_mi_scores(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svcscan.nservices                         0.681695\n",
       "svcscan.shared_process_services           0.673322\n",
       "dlllist.avg_dlls_per_proc                 0.672397\n",
       "svcscan.kernel_drivers                    0.669221\n",
       "handles.avg_handles_per_proc              0.658680\n",
       "handles.nhandles                          0.656784\n",
       "pslist.avg_handlers                       0.654955\n",
       "handles.nevent                            0.653687\n",
       "handles.nmutant                           0.652358\n",
       "handles.nsection                          0.645991\n",
       "dlllist.ndlls                             0.638625\n",
       "handles.nkey                              0.637390\n",
       "handles.nsemaphore                        0.625400\n",
       "handles.ntimer                            0.606279\n",
       "pslist.avg_threads                        0.605076\n",
       "handles.nfile                             0.596608\n",
       "handles.nthread                           0.591058\n",
       "ldrmodules.not_in_load                    0.585584\n",
       "ldrmodules.not_in_mem                     0.585277\n",
       "ldrmodules.not_in_mem_avg                 0.558161\n",
       "ldrmodules.not_in_load_avg                0.558038\n",
       "malfind.uniqueInjections                  0.555556\n",
       "ldrmodules.not_in_init                    0.522053\n",
       "ldrmodules.not_in_init_avg                0.484242\n",
       "svcscan.nactive                           0.474196\n",
       "malfind.commitCharge                      0.468938\n",
       "svcscan.process_services                  0.389619\n",
       "psxview.not_in_deskthrd_false_avg         0.358505\n",
       "pslist.nppid                              0.358406\n",
       "psxview.not_in_csrss_handles_false_avg    0.343092\n",
       "psxview.not_in_session_false_avg          0.323505\n",
       "callbacks.ncallbacks                      0.302587\n",
       "malfind.protection                        0.249368\n",
       "psxview.not_in_ethread_pool_false_avg     0.249334\n",
       "psxview.not_in_pslist_false_avg           0.225921\n",
       "psxview.not_in_pspcid_list_false_avg      0.224160\n",
       "malfind.ninjections                       0.214098\n",
       "handles.ndesktop                          0.198326\n",
       "handles.ndirectory                        0.147339\n",
       "pslist.nproc                              0.114808\n",
       "psxview.not_in_deskthrd                   0.078337\n",
       "psxview.not_in_csrss_handles              0.066976\n",
       "psxview.not_in_ethread_pool               0.066799\n",
       "psxview.not_in_pspcid_list                0.056098\n",
       "psxview.not_in_pslist                     0.055955\n",
       "psxview.not_in_session                    0.055917\n",
       "modules.nmodules                          0.007952\n",
       "psxview.not_in_eprocess_pool_false_avg    0.002523\n",
       "svcscan.fs_drivers                        0.000722\n",
       "psxview.not_in_eprocess_pool              0.000635\n",
       "callbacks.nanonymous                      0.000592\n",
       "callbacks.ngeneric                        0.000083\n",
       "svcscan.interactive_process_services      0.000000\n",
       "handles.nport                             0.000000\n",
       "pslist.nprocs64bit                        0.000000\n",
       "Name: MI Scores, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "number of features 54\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 53\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 52\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 51\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 50\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 49\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 48\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 47\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 46\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 45\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 44\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996017975994084\n",
      "=======================================================\n",
      "number of features 43\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 42\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 41\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 40\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 39\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9998293418283178\n",
      "=======================================================\n",
      "number of features 38\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9998293418283178\n",
      "=======================================================\n",
      "number of features 37\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 36\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 35\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 34\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996017975994084\n",
      "=======================================================\n",
      "number of features 33\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 32\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 31\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 30\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 29\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996586836566358\n",
      "=======================================================\n",
      "number of features 28\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 27\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 26\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 25\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 24\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 23\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 22\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996017975994084\n",
      "=======================================================\n",
      "number of features 21\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996586836566358\n",
      "=======================================================\n",
      "number of features 20\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 19\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 18\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 17\n",
      "Training accuracy: 0.9999756198649341\n",
      "Test accuracy: 0.9997724557710905\n",
      "=======================================================\n",
      "number of features 16\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9994880254849536\n",
      "=======================================================\n",
      "number of features 15\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 14\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996017975994084\n",
      "=======================================================\n",
      "number of features 13\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996017975994084\n",
      "=======================================================\n",
      "number of features 12\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9997155697138631\n",
      "=======================================================\n",
      "number of features 11\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9995449115421811\n",
      "=======================================================\n",
      "number of features 10\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9996017975994084\n",
      "=======================================================\n",
      "number of features 9\n",
      "Training accuracy: 0.9999268595948022\n",
      "Test accuracy: 0.9996017975994084\n",
      "=======================================================\n",
      "number of features 8\n",
      "Training accuracy: 0.9999268595948022\n",
      "Test accuracy: 0.9994880254849536\n",
      "=======================================================\n",
      "number of features 7\n",
      "Training accuracy: 0.9999268595948022\n",
      "Test accuracy: 0.9995449115421811\n",
      "=======================================================\n",
      "number of features 6\n",
      "Training accuracy: 0.9999024794597362\n",
      "Test accuracy: 0.9994880254849536\n",
      "=======================================================\n",
      "number of features 5\n",
      "Training accuracy: 0.9998780993246703\n",
      "Test accuracy: 0.9994311394277262\n",
      "=======================================================\n",
      "number of features 4\n",
      "Training accuracy: 0.999536777433747\n",
      "Test accuracy: 0.9981227601114967\n",
      "=======================================================\n",
      "number of features 3\n",
      "Training accuracy: 0.999536777433747\n",
      "Test accuracy: 0.9980658740542693\n",
      "=======================================================\n",
      "number of features 2\n",
      "Training accuracy: 0.9983909110856474\n",
      "Test accuracy: 0.9984071903976336\n",
      "=======================================================\n",
      "number of features 1\n",
      "Training accuracy: 0.9980495891947241\n",
      "Test accuracy: 0.9978952158825872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_temp = y\n",
    "scale = StandardScaler()\n",
    "remove_feature = []\n",
    "for feature in reversed(dict(mi_scores)):\n",
    "    remove_feature.append(feature)\n",
    "    x_temp = X.drop(columns=remove_feature)\n",
    "    if x_temp.shape[1] < 1:\n",
    "        break\n",
    "    x_temp = scale.fit_transform(x_temp)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_temp, y_temp, test_size=0.3, random_state=0, stratify=y)\n",
    "    rf = RandomForestClassifier(n_estimators=x_temp.shape[1], random_state=42)\n",
    "    clf = rf.fit(X_train,y_train)\n",
    "    print(\"=======================================================\")\n",
    "    print(f\"Number of features {x_temp.shape[1]}\")\n",
    "    print('Training accuracy:', clf.score(X_train, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Number of features 54\n",
      "Training accuracy: 0.9998049589194724\n",
      "Test accuracy: 0.8683087775186302\n",
      "=======================================================\n",
      "Number of features 53\n",
      "Training accuracy: 0.9997805787844065\n",
      "Test accuracy: 0.8685363217475397\n",
      "=======================================================\n",
      "Number of features 52\n",
      "Training accuracy: 0.9997805787844065\n",
      "Test accuracy: 0.8691620683770408\n",
      "=======================================================\n",
      "Number of features 51\n",
      "Training accuracy: 0.9998537191896043\n",
      "Test accuracy: 0.8698447010637693\n",
      "=======================================================\n",
      "Number of features 50\n",
      "Training accuracy: 0.9998780993246703\n",
      "Test accuracy: 0.8677399169463564\n",
      "=======================================================\n",
      "Number of features 49\n",
      "Training accuracy: 0.9997805787844065\n",
      "Test accuracy: 0.8669435121451732\n",
      "=======================================================\n",
      "Number of features 48\n",
      "Training accuracy: 0.9997805787844065\n",
      "Test accuracy: 0.8675692587746743\n",
      "=======================================================\n",
      "Number of features 47\n",
      "Training accuracy: 0.9998537191896043\n",
      "Test accuracy: 0.8666590818590364\n",
      "=======================================================\n",
      "Number of features 46\n",
      "Training accuracy: 0.9998049589194724\n",
      "Test accuracy: 0.8688776380909039\n",
      "=======================================================\n",
      "Number of features 45\n",
      "Training accuracy: 0.9998049589194724\n",
      "Test accuracy: 0.8672848284885375\n",
      "=======================================================\n",
      "Number of features 44\n",
      "Training accuracy: 0.9997318185142746\n",
      "Test accuracy: 0.8696740428920872\n",
      "=======================================================\n",
      "Number of features 43\n",
      "Training accuracy: 0.9997805787844065\n",
      "Test accuracy: 0.8705842198077252\n",
      "=======================================================\n",
      "Number of features 42\n",
      "Training accuracy: 0.9996830582441427\n",
      "Test accuracy: 0.8691620683770408\n",
      "=======================================================\n",
      "Number of features 41\n",
      "Training accuracy: 0.9997805787844065\n",
      "Test accuracy: 0.8709255361510894\n",
      "=======================================================\n",
      "Number of features 40\n",
      "Training accuracy: 0.9997074383792086\n",
      "Test accuracy: 0.8688207520336766\n",
      "=======================================================\n",
      "Number of features 39\n",
      "Training accuracy: 0.9997561986493405\n",
      "Test accuracy: 0.8710961943227715\n",
      "=======================================================\n",
      "Number of features 38\n",
      "Training accuracy: 0.9997074383792086\n",
      "Test accuracy: 0.8697309289493145\n",
      "=======================================================\n",
      "Number of features 37\n",
      "Training accuracy: 0.9996586781090767\n",
      "Test accuracy: 0.8716650548950452\n",
      "=======================================================\n",
      "Number of features 36\n",
      "Training accuracy: 0.9995611575688129\n",
      "Test accuracy: 0.8691051823198134\n",
      "=======================================================\n",
      "Number of features 35\n",
      "Training accuracy: 0.9996099178389448\n",
      "Test accuracy: 0.8702429034643608\n",
      "=======================================================\n",
      "Number of features 34\n",
      "Training accuracy: 0.9996586781090767\n",
      "Test accuracy: 0.8710393082655441\n",
      "=======================================================\n",
      "Number of features 33\n",
      "Training accuracy: 0.999512397298681\n",
      "Test accuracy: 0.8713806246089083\n",
      "=======================================================\n",
      "Number of features 32\n",
      "Training accuracy: 0.999512397298681\n",
      "Test accuracy: 0.8716650548950452\n",
      "=======================================================\n",
      "Number of features 31\n",
      "Training accuracy: 0.9992685959480215\n",
      "Test accuracy: 0.8683656635758575\n",
      "=======================================================\n",
      "Number of features 30\n",
      "Training accuracy: 0.9991710754077577\n",
      "Test accuracy: 0.8687638659764492\n",
      "=======================================================\n",
      "Number of features 29\n",
      "Training accuracy: 0.99909793500256\n",
      "Test accuracy: 0.8716081688378179\n",
      "=======================================================\n",
      "Number of features 28\n",
      "Training accuracy: 0.9989516541921643\n",
      "Test accuracy: 0.869332726548723\n",
      "=======================================================\n",
      "Number of features 27\n",
      "Training accuracy: 0.9979276885193944\n",
      "Test accuracy: 0.8692758404914955\n",
      "=======================================================\n",
      "Number of features 26\n",
      "Training accuracy: 0.9980495891947241\n",
      "Test accuracy: 0.8700153592354514\n",
      "=======================================================\n",
      "Number of features 25\n",
      "Training accuracy: 0.9977570275739328\n",
      "Test accuracy: 0.8696171568348597\n",
      "=======================================================\n",
      "Number of features 24\n",
      "Training accuracy: 0.9979520686544604\n",
      "Test accuracy: 0.8672279424313101\n",
      "=======================================================\n",
      "Number of features 23\n",
      "Training accuracy: 0.9980008289245922\n",
      "Test accuracy: 0.8686500938619944\n",
      "=======================================================\n",
      "Number of features 22\n",
      "Training accuracy: 0.9976107467635371\n",
      "Test accuracy: 0.8658057910006257\n",
      "=======================================================\n",
      "Number of features 21\n",
      "Training accuracy: 0.9975863666284711\n",
      "Test accuracy: 0.8615962227658001\n",
      "=======================================================\n",
      "Number of features 20\n",
      "Training accuracy: 0.9972694248726138\n",
      "Test accuracy: 0.864781841970533\n",
      "=======================================================\n",
      "Number of features 19\n",
      "Training accuracy: 0.9970500036570202\n",
      "Test accuracy: 0.8626201717958928\n",
      "=======================================================\n",
      "Number of features 18\n",
      "Training accuracy: 0.9968793427115586\n",
      "Test accuracy: 0.861425564594118\n",
      "=======================================================\n",
      "Number of features 17\n",
      "Training accuracy: 0.9963673598751737\n",
      "Test accuracy: 0.8452699243415439\n",
      "=======================================================\n",
      "Number of features 16\n",
      "Training accuracy: 0.9956115756881293\n",
      "Test accuracy: 0.8476022526878662\n",
      "=======================================================\n",
      "Number of features 15\n",
      "Training accuracy: 0.993880586098447\n",
      "Test accuracy: 0.8337220547243871\n",
      "=======================================================\n",
      "Number of features 14\n",
      "Training accuracy: 0.9873223297657069\n",
      "Test accuracy: 0.8301382331190625\n",
      "=======================================================\n",
      "Number of features 13\n",
      "Training accuracy: 0.9872248092254431\n",
      "Test accuracy: 0.8278627908299676\n",
      "=======================================================\n",
      "Number of features 12\n",
      "Training accuracy: 0.9859814223370797\n",
      "Test accuracy: 0.8170544399567666\n",
      "=======================================================\n",
      "Number of features 11\n",
      "Training accuracy: 0.9797644878952629\n",
      "Test accuracy: 0.7956083963820467\n",
      "=======================================================\n",
      "Number of features 10\n",
      "Training accuracy: 0.9776921764146573\n",
      "Test accuracy: 0.7895215882587178\n",
      "=======================================================\n",
      "Number of features 9\n",
      "Training accuracy: 0.9693054099519711\n",
      "Test accuracy: 0.781329996017976\n",
      "=======================================================\n",
      "Number of features 8\n",
      "Training accuracy: 0.9647463246946388\n",
      "Test accuracy: 0.7686444052562716\n",
      "=======================================================\n",
      "Number of features 7\n",
      "Training accuracy: 0.9185703488797328\n",
      "Test accuracy: 0.7579498264975254\n",
      "=======================================================\n",
      "Number of features 6\n",
      "Training accuracy: 0.9139625033522686\n",
      "Test accuracy: 0.7606803572444394\n",
      "=======================================================\n",
      "Number of features 5\n",
      "Training accuracy: 0.9093790379598703\n",
      "Test accuracy: 0.7550486375789294\n",
      "=======================================================\n",
      "Number of features 4\n",
      "Training accuracy: 0.7881366262769096\n",
      "Test accuracy: 0.7557881563228852\n",
      "=======================================================\n",
      "Number of features 3\n",
      "Training accuracy: 0.7864056366872273\n",
      "Test accuracy: 0.7535127140337903\n",
      "=======================================================\n",
      "Number of features 2\n",
      "Training accuracy: 0.6742570153838652\n",
      "Test accuracy: 0.6697764377950964\n",
      "=======================================================\n",
      "Number of features 1\n",
      "Training accuracy: 0.6741107345734695\n",
      "Test accuracy: 0.669548893566187\n"
     ]
    }
   ],
   "source": [
    "y_temp = malware_data.Category\n",
    "y_temp = class_le.fit_transform(y_temp)\n",
    "# scale = StandardScaler()\n",
    "remove_feature = []\n",
    "for feature in reversed(dict(mi_scores)):\n",
    "    remove_feature.append(feature)\n",
    "    x_temp = X.drop(columns=remove_feature)\n",
    "    if x_temp.shape[1] < 1:\n",
    "        break\n",
    "    # x_temp = scale.fit_transform(x_temp)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_temp, y_temp, test_size=0.3, random_state=0, stratify=y)\n",
    "    rf = RandomForestClassifier(n_estimators=x_temp.shape[1], random_state=42)\n",
    "    clf = rf.fit(X_train,y_train)\n",
    "    print(\"=======================================================\")\n",
    "    print(f\"Number of features {x_temp.shape[1]}\")\n",
    "    print('Training accuracy:', clf.score(X_train, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.:[26368 26368], Acc: 0.999\n",
      "Fold: 2, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 3, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 4, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 5, Class dist.:[26368 26368], Acc: 0.990\n",
      "Fold: 6, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 7, Class dist.:[26368 26369], Acc: 0.999\n",
      "Fold: 8, Class dist.:[26368 26369], Acc: 1.000\n",
      "Fold: 9, Class dist.:[26369 26368], Acc: 1.000\n",
      "Fold:10, Class dist.:[26369 26368], Acc: 1.000\n"
     ]
    }
   ],
   "source": [
    "y_temp = malware_data.Class\n",
    "y_temp = class_le.fit_transform(y_temp)\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "X_sc = scale.fit_transform(X)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold.split(X_sc, y_temp)): # iterator\n",
    "    rf_model = RandomForestClassifier(n_estimators=X_sc.shape[1], random_state=42)\n",
    "    #print(train.shape, test.shape)\n",
    "    rf_model.fit(X_sc[train], y_temp[train])\n",
    "    score = rf_model.score(X_sc[test], y_temp[test])\n",
    "    scores.append(score)\n",
    "    print(f'Fold:{k+1:2d}, Class dist.:{np.bincount(y_temp[train])}, Acc: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.:[26368  8812  9018  8538], Acc: 0.759\n",
      "Fold: 2, Class dist.:[26368  8812  9018  8538], Acc: 0.792\n",
      "Fold: 3, Class dist.:[26368  8812  9018  8538], Acc: 0.844\n",
      "Fold: 4, Class dist.:[26368  8812  9018  8538], Acc: 0.865\n",
      "Fold: 5, Class dist.:[26368  8812  9018  8538], Acc: 0.874\n",
      "Fold: 6, Class dist.:[26368  8812  9018  8538], Acc: 0.857\n",
      "Fold: 7, Class dist.:[26368  8812  9018  8539], Acc: 0.851\n",
      "Fold: 8, Class dist.:[26368  8812  9018  8539], Acc: 0.853\n",
      "Fold: 9, Class dist.:[26369  8811  9018  8539], Acc: 0.806\n",
      "Fold:10, Class dist.:[26369  8812  9018  8538], Acc: 0.812\n"
     ]
    }
   ],
   "source": [
    "y_temp = malware_data.Category\n",
    "y_temp = class_le.fit_transform(y_temp)\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "X_sc = scale.fit_transform(X)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold.split(X_sc, y_temp)): # iterator\n",
    "    rf_model = RandomForestClassifier(n_estimators=X_sc.shape[1], random_state=42)\n",
    "    #print(train.shape, test.shape)\n",
    "    rf_model.fit(X_sc[train], y_temp[train])\n",
    "    score = rf_model.score(X_sc[test], y_temp[test])\n",
    "    scores.append(score)\n",
    "    print(f'Fold:{k+1:2d}, Class dist.:{np.bincount(y_temp[train])}, Acc: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 2, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 3, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 4, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 5, Class dist.:[26368 26368], Acc: 0.990\n",
      "Fold: 6, Class dist.:[26368 26368], Acc: 1.000\n",
      "Fold: 7, Class dist.:[26368 26369], Acc: 0.999\n",
      "Fold: 8, Class dist.:[26368 26369], Acc: 1.000\n",
      "Fold: 9, Class dist.:[26369 26368], Acc: 1.000\n",
      "Fold:10, Class dist.:[26369 26368], Acc: 1.000\n"
     ]
    }
   ],
   "source": [
    "y_temp = malware_data.Class\n",
    "y_temp = class_le.fit_transform(y_temp)\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold.split(X, y_temp)): # iterator\n",
    "    rf_model = RandomForestClassifier(n_estimators=X.shape[1], random_state=42)\n",
    "    #print(train.shape, test.shape)\n",
    "    rf_model.fit(X.values[train], y_temp[train])\n",
    "    score = rf_model.score(X.values[test], y_temp[test])\n",
    "    scores.append(score)\n",
    "    print(f'Fold:{k+1:2d}, Class dist.:{np.bincount(y_temp[train])}, Acc: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.:[26368  8812  9018  8538], Acc: 0.758\n",
      "Fold: 2, Class dist.:[26368  8812  9018  8538], Acc: 0.792\n",
      "Fold: 3, Class dist.:[26368  8812  9018  8538], Acc: 0.844\n",
      "Fold: 4, Class dist.:[26368  8812  9018  8538], Acc: 0.865\n",
      "Fold: 5, Class dist.:[26368  8812  9018  8538], Acc: 0.875\n",
      "Fold: 6, Class dist.:[26368  8812  9018  8538], Acc: 0.857\n",
      "Fold: 7, Class dist.:[26368  8812  9018  8539], Acc: 0.851\n",
      "Fold: 8, Class dist.:[26368  8812  9018  8539], Acc: 0.851\n",
      "Fold: 9, Class dist.:[26369  8811  9018  8539], Acc: 0.806\n",
      "Fold:10, Class dist.:[26369  8812  9018  8538], Acc: 0.811\n"
     ]
    }
   ],
   "source": [
    "y_temp = malware_data.Category\n",
    "y_temp = class_le.fit_transform(y_temp)\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold.split(X, y_temp)): # iterator\n",
    "    rf_model = RandomForestClassifier(n_estimators=X.shape[1], random_state=42)\n",
    "    #print(train.shape, test.shape)\n",
    "    rf_model.fit(X.values[train], y_temp[train])\n",
    "    score = rf_model.score(X.values[test], y_temp[test])\n",
    "    scores.append(score)\n",
    "    print(f'Fold:{k+1:2d}, Class dist.:{np.bincount(y_temp[train])}, Acc: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99982935 0.99991467 0.99488011 0.99957334 1.        ]\n",
      "Mean: 0.9988394943365211 \n",
      " std: 0.0019848351882600142\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=X.shape[1], random_state=42)\n",
    "cvs = cross_val_score(estimator=rf, X=X, y=y, n_jobs=-1)\n",
    "print(cvs)\n",
    "print(f\"Mean: {cvs.mean()} \\n std: {cvs.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malware_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
